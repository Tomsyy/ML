{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset\n",
      "0 documents\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/thomas/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "from sentimentanalysis import *\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "from nltk import SnowballStemmer\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "directement dans le code.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On charges les 2000 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset\n",
      "2000 documents\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset\")\n",
    "\n",
    "from glob import glob\n",
    "filenames_neg = sorted(glob(op.join('34data', 'data', 'imdb1', 'neg', '*.txt')))\n",
    "filenames_pos = sorted(glob(op.join('34data', 'data', 'imdb1', 'pos', '*.txt')))\n",
    "\n",
    "texts_neg = [open(f).read() for f in filenames_neg]\n",
    "texts_pos = [open(f).read() for f in filenames_pos]\n",
    "texts = texts_neg + texts_pos\n",
    "y = np.ones(len(texts), dtype=np.int)\n",
    "y[:len(texts_neg)] = 0.\n",
    "\n",
    "print(\"%d documents\" % len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50920"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc, table = count_words(texts)\n",
    "len(voc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- In order to obtain more accurate rating decisions, the maximum\n",
    "\trating must be specified explicitly, both for numerical ratings\n",
    "\tand star ratings.  (\"8/10\", \"four out of five\", and \"OUT OF\n",
    "\t****: ***\" are examples of rating indications we recognize.)\n",
    "\n",
    "- With a five-star system (or compatible number systems):\n",
    "\tthree-and-a-half stars and up are considered positive, \n",
    "\ttwo stars and below are considered negative.\n",
    "- With a four-star system (or compatible number system):\n",
    "\tthree stars and up are considered positive, \n",
    "\tone-and-a-half stars and below are considered negative.  \n",
    "- With a letter grade system:\n",
    "\tB or above is considered positive,\n",
    "\tC- or below is considered negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilisation de Sickit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transformation de nos données pour effectuer les modèles et création d'un dataset train et test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39659\n"
     ]
    }
   ],
   "source": [
    "corpus = texts\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(len(vectorizer.get_feature_names()))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ErrorRate(Y_estim, Y):\n",
    "    '''Fonction qui calcule le taux d\\'erreur '''\n",
    "    Y_error = Y_estim - Y\n",
    "    Error_Rate = len(Y_error[Y_error!=0]) / len(Y_error)\n",
    "    print('le taux d\\'erreur sur les données de test vaut', round(Error_Rate,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le taux d'erreur sur les données de test vaut 0.213\n"
     ]
    }
   ],
   "source": [
    "Nb = MultinomialNB()\n",
    "Nb.fit(X_train, y_train)\n",
    "ErrorRate(Nb.predict(X_test), y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### création d'une pipeline avec GridSearch pour le Naives Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline : ['vect', 'clf']\n",
      "parameters :\n",
      "{'clf__alpha': (0.1, 1, 2, 3),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2))}\n",
      "done in 144.612s\n",
      "\n",
      "Best score: 0.838\n",
      "Best parameters set :\n",
      "\tclf__alpha: 1\n",
      "\tvect__max_df: 0.75\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range = (2,2)) ),\n",
    "    ('clf', MultinomialNB()),\n",
    "    ])\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),       # ignore terms that have a document frequency strictly higher than the given threshold\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'clf__alpha': (0.1,1,2,3),                # additive (Laplace/Lidstone) smoothing parameter\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5, verbose=0, n_jobs=-1)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline :\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters :\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "grid_search.fit(texts, y)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set :\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline pour tester plusieurs modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline : ['vect', 'lr']\n",
      "parameters :\n",
      "{'lr__penalty': ('l1', 'l2'), 'vect__max_df': (0.67, 0.7, 0.72)}\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 86.349s\n",
      "\n",
      "Best score: 0.854\n",
      "Best parameters set :\n",
      "\tlr__penalty: 'l2'\n",
      "\tvect__max_df: 0.67\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "multiNB_pipe = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range=(1, 2)) ),\n",
    "    ('multiNB', MultinomialNB() ),\n",
    "    ])\n",
    "\n",
    "svc_pipe = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range=(1, 2)) ),\n",
    "    ('svc', LinearSVC(penalty='l2', random_state=2) ),\n",
    "    ])\n",
    "\n",
    "lr_pipe = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range=(1, 2)) ),\n",
    "    ('lr', LogisticRegression(random_state=2) ),\n",
    "    ])\n",
    "\n",
    "parameters= {\n",
    "    'vect__max_df':(0.67, 0.7, 0.72),\n",
    "#    'vect__ngram_range':((1, 1),(1, 2)),\n",
    "\n",
    "#    'multiNB__alpha' : (0.8, 1),\n",
    "#    'svc__loss': ('squared_hinge', 'hinge'),\n",
    "\n",
    "    'lr__penalty': ('l1','l2'),\n",
    "}\n",
    "\n",
    "\n",
    "pipeline = lr_pipe\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid=parameters, cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline :\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters :\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "grid_search.fit(texts, y)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set :\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# permet de remplacer les mots par leur racinisation\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "test = texts\n",
    "all_list = []\n",
    "\n",
    "for iloop in range(len(test)):\n",
    "    new_words_list = []\n",
    "    for rep1 in test[iloop].split():\n",
    "        add = stemmer.stem(rep1.split(' ')[0])\n",
    "        new_words_list.append(add)\n",
    "        \n",
    "    all_list.append(' '.join(new_words_list))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline : ['vect', 'clf']\n",
      "parameters :\n",
      "{'clf__alpha': (0.1, 1, 2, 3),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2))}\n",
      "done in 142.614s\n",
      "\n",
      "Best score: 0.833\n",
      "Best parameters set :\n",
      "\tclf__alpha: 1\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range = (2,2)) ),\n",
    "    ('clf', MultinomialNB()),\n",
    "    ])\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),       # ignore terms that have a document frequency strictly higher than the given threshold\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'clf__alpha': (0.1,1,2,3),                # additive (Laplace/Lidstone) smoothing parameter\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5, verbose=0, n_jobs=-1)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline :\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters :\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "grid_search.fit(all_list, y)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set :\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sous linux aller dans le terminal est insérer\n",
    "# python -m nltk.downloader 'punkt'\n",
    "# python -m nltk.downloader 'averaged_perceptron_tagger'\n",
    "\n",
    "# ou \n",
    "#import nltk as nltk\n",
    "#nltk.download()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestPo = texts\n",
    "Token_list = []\n",
    "\n",
    "for iloop in range(len(TestPo)):\n",
    "    Token_list.append(word_tokenize(TestPo[iloop]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text_pos_tag = [pos_tag(sent) for sent in Token_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on ne garde que les mots qui sont des noms, adjectifs, adverbes ou des verbes\n",
    "grammar = 'NN','NNS','NNP','NNPS','VB','VBD','VBG','VBN','VBP','VBZ','JJ','JJR','JJS','RB','RBR','RBS'\n",
    "final_list = []\n",
    "for iloop in range(len(Text_pos_tag)):\n",
    "    good_words_list = []\n",
    "    for jloop in range(len(Text_pos_tag[iloop])):\n",
    "        if Text_pos_tag[iloop][jloop][1] in grammar:\n",
    "            good_words_list.append(Text_pos_tag[iloop][jloop][0])\n",
    "    \n",
    "    final_list.append(' '.join(good_words_list))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline : ['vect', 'clf']\n",
      "parameters :\n",
      "{'clf__alpha': (0.1, 1, 2, 3),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2))}\n",
      "done in 108.255s\n",
      "\n",
      "Best score: 0.828\n",
      "Best parameters set :\n",
      "\tclf__alpha: 1\n",
      "\tvect__max_df: 0.75\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range = (2,2)) ),\n",
    "    ('clf', MultinomialNB()),\n",
    "    ])\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),       # ignore terms that have a document frequency strictly higher than the given threshold\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'clf__alpha': (0.1,1,2,3),                # additive (Laplace/Lidstone) smoothing parameter\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5, verbose=0, n_jobs=-1)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline :\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters :\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "grid_search.fit(final_list, y)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set :\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CC coordinating conjunction\n",
    "CD cardinal digit\n",
    "DT determiner\n",
    "EX existential there (like: “there is” … think of it like “there exists”)\n",
    "FW foreign word\n",
    "IN preposition/subordinating conjunction\n",
    "JJ adjective ‘big’\n",
    "JJR adjective, comparative ‘bigger’\n",
    "JJS adjective, superlative ‘biggest’\n",
    "LS list marker 1)\n",
    "MD modal could, will\n",
    "NN noun, singular ‘desk’\n",
    "NNS noun plural ‘desks’\n",
    "NNP proper noun, singular ‘Harrison’\n",
    "NNPS proper noun, plural ‘Americans’\n",
    "PDT predeterminer ‘all the kids’\n",
    "POS possessive ending parent’s\n",
    "PRP personal pronoun I, he, she\n",
    "PRP$ possessive pronoun my, his, hers\n",
    "RB adverb very, silently,\n",
    "RBR adverb, comparative better\n",
    "RBS adverb, superlative best\n",
    "RP particle give up\n",
    "TO, to go ‘to’ the store.\n",
    "UH interjection, errrrrrrrm\n",
    "VB verb, base form take\n",
    "VBD verb, past tense took\n",
    "VBG verb, gerund/present participle taking\n",
    "VBN verb, past participle taken\n",
    "VBP verb, sing. present, non-3d take\n",
    "VBZ verb, 3rd person sing. present takes\n",
    "WDT wh-determiner which\n",
    "WP wh-pronoun who, what\n",
    "WP$ possessive wh-pronoun whose\n",
    "WRB wh-abverb where, when"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
